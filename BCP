the following are the Best Current Practices for the code in this branch.
generally speaking, any instance of code that goes against this BCP is just because it's older code prior to these BCP and hasn't been updated yet.

- first, go read https://wiki.ubuntu.com/DashAsBinSh.  if you think you already know everything there, just go read it anyway because it's heartwarming to find someone laying out such an agreeable BCP.  anything covered there will be omitted here.  everything covered there is recommended to be followed.

- thinking is hard and takes time.  don't write "clever" or "cool looking" code.  the kind of code which provides masturbatory satisfaction when it's written and shown to a small circle of admirers nearly always causes other people who have to deal with its failure later to want to kill the author because debugging it during an outage or after a bad day of being stuck in other crappy code royally sucks and nobody is laughing then.

- these guidelines are meant to optimize on both portability and readability, as that is where most shell code falls short.  

# INTERPRETER LINE (see http://www.openbsd.org/cgi-bin/man.cgi/OpenBSD-current/man7/script.7?query=script&sec=7 if you don't understand the term)
- make an effort by default to make code compatible with dash(1).  dash is /bin/sh on a few contemporary GNU distributions (debian, ubuntu, ...).  
- prefer an interpreter line of just '/bin/sh' by default.  if specifying 'bash' or 'ksh' or 'zsh' is *required* or not using one of them would otherwise harm the readability of the script, use the /usr/bin/env trampoline instead of hardcoding the path to the shell.  hardcoding it is harmful to portability.
- said another way, any script that is not dash(1)-compatible ought to be declared to run with 'bash' or 'ksh' or 'zsh' or whatever as above.
- do not pass shell arguments on the interpreter line.  e.g.: don't '#!/bin/sh -e'.  rather, just '#!/bin/sh' and then 'set -e' below.

# PARAMETERS
- arrays are not supported by dash.  in shells that support them, interacting with arrays is generally slower than with regular parameters.
- there is no portable one-shot way to set an array.  bash uses 'array=( one two three four )' and ksh uses 'set -A array one two three four'.  a portable option is to do a for-loop with an increasing iterator, similar to:
	x=0
	for value in one two three four; do
		array[$x]=$value
		x=$(( x + 1 ))
	done
- in parameter assignment where the RHS/value is a single bareword, quotes are not necessary.  otherwise, quote the RHS/value.
- while it is completely safe to leave the 'word' in a case statement unquoted, just quote it anyway because there's no value in leaving it unquoted
- quote ALL parameter dereferences (e.g.: when you say "$PARAMETER") in every case other than in arithmetic expressions.  quoting them in arithmetic can be counterproductive as a null valued parameter will evaluate to '0' when unquoted, but '' when quoted.
- inside arithmetic expressions, in the rare case where doing so increases code clarity (or when actual assignment is being performed therein), it is acceptable to omit the '$' sign.
- in most cases, the double-quoted "$@" is what you want to use to refer to the arguments given to the script or a function.  the desired/legit uses for '$*' are relatively rare.
- keep parameter names consistent with commandline/function argument descriptions.  e.g.: if usage() says: "... [-m module_name]", then use 'module_name' as the name of the parameter in the corresponding code, don't abbreviate it to 'modname' or something.

# EVALUATIONS
- again, always quote parameters
- never && do crap || like this.  it is harder to read than a properly fleshed out if-clause and optimizes for character count instead of comprehension time.  it can be said that the Apple OpenSSL bug that happened is entirely because of people's insistence on using unencapsulated post-conditional clauses like this "style" encourages.
- prefer 'case' for any instance of textual comparison.  'case' is slightly faster than '[' and is generally easier to read.  most importantly, 'case' is safer and harder to shoot yourself in the foot.
- prefer 'case' for boolean numerical comparison.  if something is more than boolean, then go ahead and use '['
- prefer getopts builtin over userland getopt(1).  builtins are faster and getopt(1) is clunkier to use.
- never compare a supposedly numeric parameter against anything before ensuring it's numeric.  shell code cannot be considered well written if there is ever a syntax error to '[', such as "unary operator expected".
- in general it is usually easier to read to test the failure case first, handle that in the post-conditional clause, and then have success be handled outside.  e.g.:
(don't do this):
	if true; then
		bunch of
		lines because
		something good
		happened
	else
		oh crap
		something bad
	fi

(do this instead):
	if ! true; then
		oh crap
		something bad
	fi
	bunch of
	lines because
	something good
	happened

# SUBSTITUTIONS
- do not use backticks.  doing so just makes you look like you haven't written a shell script since sh(1) on solaris, which implies you probably write crappy shell.  use '$( ... )'.  it is better supported in editors for syntax highlighting and navigation, allows nested subsitutions, and handles nested quotes without issue.
- furthermore, leave your "eval 1 + 2" back on 1982's doorstep where it belongs.  all contemporary shells support '$(( ... ))' arithmetic subsitutions.
- avoid nested subsitutions because they're hard to read.
- avoid pipes in command subsitutions whose output is assigned to a variable.  prefer instead to just get your output into the variable and then munge it afterwards.  the exit status of a pipeline being tested is that of the last command.  nothing prior has any significance.  if a complex pipeline must be used, consider using a grep for expected-string as the last command, as that will error out if the string is not found.  if you are simply testing for the existence or non-existence of text, consider using 'grep -q .' at the end.

# FORMAT
- in general follow this format:
1) interpreter
2) shell options/twiddles (like 'set -e')
3) global parameters or user-definable settings
4) a usage() function (
5) the rest of the functions in alphabetical order
6) (optional, might not be needed)
 a) getopts loop followed by parameter checking after the loop.
7) actual code that does work.
- section markers like "####### FUNCTIONS ##########" and  "## ---------------------------[ MAIN ]-----------------------------" are to be avoided.  it is better to have clear code which is self-evident than a bunch of amateur-hour poop-soup with big flagpoles sticking out of it.

# FUNCTIONS
- prefer "open brace on nextline", as this is what the '[[' and ']]' shortcuts in vi(1) are designed to take advantage of.
- avoid prepending underscores to variables to avoid potential namespace collisions.  use 'local'.
- functions of nontrivial nature ought to have, at the top:
	local funcname=functions_actual_name
	local usage="$funcname(): usage: $funcname <actual usage>".
  it is true that keeping $funcname in synch with the actual function name is a manual effort which is prone to error, however keeping this standard format allows for very easy emission of useful error messages 
- avoid calling functions from within a getopts loop.  OPTIND is always global (i.e.: ``local OPTIND'' does not do what you think it does), and functions may want to call getopts themselves.

# LOOPS
- any loop that would run forever if there was no code inside it ought to have a 'break' failsafe as the last line before 'done', and then an explicit test performed prior to that to indicate that 'continue'ing is desired.  this is a highly useful guard against human error.
- any loop which "feeds" off a successful glob must have as its first component a test to see if that glob even occurred.  e.g.:
	for filename in /etc/*; do
		case "$filename" in
		'/etc/*')
			# oh crap if /etc is empty, /etc/* won't not expand to anything and
			# so the shell just interpreted it as a literal string!
			# oh crap we should bail
			break
			;;
		esac
		ok now
		do stuff
	done

# USERLAND
- in nearly all cases, reaching out to the userland is more performance-expensive than running internal/builtin commands.  consider keeping things internal if there is no harm to readability.
- do not hardcode paths to binaries.  instead, lean on PATH as much as you need.  modify it if desired/required.  different distros put stuff wherever they want, and heir(7) means different things to different people.  clutter up PATH if you need to.  that's what it is there for.
- prefer portable userland commands.  'pkill' and 'pgrep' are more prolific than 'killall' and 'pidof'
- avoid non-portable uses of userland commands.  e.g.: openbsd grep-and-friends support the '[:>:]' and '[:<:]' character classes, however these are not specified by POSIX and don't generally appear elsewhere.
- be specifically cautious when passing arguments to 

# MISC
- always use 'set -e' and always test everything that could potentially fail.  code with 'set -e' in place which happens to miss capturing an operation which ends up failing *can* be cumbersome to debug, however this situation is far better than omitting 'set -e' and having the code just plow on after a failure it otherwise ought to have not proceeded past.  always using 'set -e' is a safety measure.  some people say they don't need to wear seatbelts because they "know what they are doing".  professional race drivers always wear multiple safety harnesses/measures, however.
- avoid 'cd' anywhere.  well-written shell code does not need to go to a specific place to do its work.  requiring a change to PWD also makes it harder to debug.
- in general it is better to let STDERR out of the bag instead of collecting it yourself.  if you grew up on perl you might be used to checking/grepping perl's "$@" to see if something went wrong.  in shell, always rely primarily on exit values unless the exit values end up being meaningless.  furthermore, if you capture STDERR and pass it up the function chain, it can appear in a reverse order which is confusing.
- if there is ever a time the script invokes mktemp(1), include an EXIT trap that performs a cleanup.  if you want to provide the option to keep that temp stuff around, provide an argument such as '-k -- keep' that resets the EXIT trap back to its default.
- prefer 'while ! thing' over 'until thing'.  we don't need both 'while' and 'until'.  thinking is hard and t.
- prefer '[ ! -z "$thing" ]' over '[ -n "$thing" ]'.  "! -z" reads as "not zero", '-n' generally connotes a 'noop' mode, and thinking is hard.
- longhand is almost always easier to read than shorthand.  burn a few lines in your code.  burn a tmpfile on disk instead of trying to '| sed | awk | whatever' the crap out of a parameter.
